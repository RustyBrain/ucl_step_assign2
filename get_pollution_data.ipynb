{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_construct = \"https://fme.discomap.eea.europa.eu/fmedatastreaming/AirQualityDownload/AQData_Extract.fmw?CountryCode={}&CityName={}&Pollutant={}&Year_from=2016&Year_to=2020&Station=&Samplingpoint=&Source=E1a&Output=HTML&UpdateDate=&TimeCoverage=Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [{'country': 'GB', 'city': 'London'},\n",
    "          {'country': 'GB', 'city': 'Greater%20Manchester'},\n",
    "          {'country': 'PL', 'city': 'Krak%C3%B3w'},\n",
    "          {'country': 'NL', 'city': 'Amsterdam'},\n",
    "          {'country': 'IT', 'city': 'Milano'},\n",
    "          {'country': 'FR', 'city': 'Paris'},\n",
    "          {'country': 'ES', 'city': 'Madrid'},\n",
    "          {'country': 'DE', 'city': 'Berlin'},\n",
    "          {'country': 'DE', 'city': 'Frankfurt%20am%20Main'},\n",
    "         ]\n",
    "pollutants = ['5', '6001', '9', '8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test stuff\n",
    "# soup = BeautifulSoup(r.content, 'lxml')\n",
    "# links = []\n",
    "# for link in soup.findAll('a', attrs={'href': re.compile(\"^https://\")}):\n",
    "#     links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for link in links:\n",
    "#     df = pd.read_csv(link)\n",
    "#     df['datetime'] = pd.to_datetime(df['DatetimeBegin'], errors='coerce', infer_datetime_format=True) \n",
    "#     df['hour'] = df['datetime'].dt.hour\n",
    "#     df['year'] = df['datetime'].dt.year\n",
    "#     low = df[df['hour'] == 2]\n",
    "#     high = df[df['hour'] == 17]\n",
    "#     dat = {\n",
    "#         'city': 'London',\n",
    "#         'site': df['AirQualityStation'].iloc[0],\n",
    "#         'pollutant': df['AirPollutant'].iloc[0],\n",
    "#         'year': df['year'].iloc[0],\n",
    "#         'low': low['Concentration'].mean(),\n",
    "#         'high': high['Concentration'].mean(),\n",
    "#         'measurement': df['UnitOfMeasurement'].iloc[0]\n",
    "#     }\n",
    "#     master_df = master_df.append(dat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame()\n",
    "for city in cities:\n",
    "    for pollutant in pollutants:\n",
    "        url = url_construct.format(city['country'], city['city'], pollutant)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, 'lxml')\n",
    "        links = []\n",
    "        for link in soup.findAll('a', attrs={'href': re.compile(\"^https://\")}):\n",
    "            links.append(link.get('href'))\n",
    "        for link in links:\n",
    "            df = pd.read_csv(link)\n",
    "            df['datetime'] = pd.to_datetime(df['DatetimeBegin'], errors='coerce', infer_datetime_format=True) \n",
    "            df['hour'] = df['datetime'].dt.hour\n",
    "            df['year'] = df['datetime'].dt.year\n",
    "            low = df[df['hour'] == 2]\n",
    "            high = df[df['hour'] == 17]\n",
    "            midnight = df[df['hour'] == 0]\n",
    "            dat = {\n",
    "                'city': city['city'],\n",
    "                'site': df['AirQualityStation'].iloc[0],\n",
    "                'pollutant': df['AirPollutant'].iloc[0],\n",
    "                'year': df['year'].iloc[0],\n",
    "                'low': low['Concentration'].mean(),\n",
    "                'high': high['Concentration'].mean(),\n",
    "                'midnight': midnight['Concentration'].mean(),\n",
    "                'measurement': df['UnitOfMeasurement'].iloc[0]\n",
    "            }\n",
    "            master_df = master_df.append(dat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (mapping_pollution)",
   "language": "python",
   "name": "pycharm-d484ab97"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
